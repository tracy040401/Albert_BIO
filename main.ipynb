{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import numpy as np\n",
    "import emb_spacy\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional, GRU\n",
    "from keras.metrics import Accuracy, Precision, Recall, F1Score, MeanSquaredError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from emb_spacy import get_embedding\n",
    "from input import count_examples_and_max_length, pad_sentences_from_file\n",
    "import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples : 3945\n",
      "Taille maximale de la phrase : 41\n",
      "vecteur :  (3945, 41)\n"
     ]
    }
   ],
   "source": [
    "# Ouverture en lecture des données\n",
    "with open(\"train_corpus\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Compter les exemples et trouver la taille maximale\n",
    "num_examples, MAX_SEQ_SIZE = count_examples_and_max_length(data)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Nombre d'exemples :\", num_examples) \n",
    "print(\"Taille maximale de la phrase :\", MAX_SEQ_SIZE)\n",
    "\n",
    "vec_word, sortie = pad_sentences_from_file(\"train_corpus\", MAX_SEQ_SIZE)\n",
    "print(\"vecteur : \", vec_word.shape)\n",
    "# vec_word.shape : (3945, 41)\n",
    "# sortie.shape : (3945, 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des vecteurs d'entrée et de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entree shape :  (3945, 41, 300)\n",
      "sortie shape :  (3945, 41)\n"
     ]
    }
   ],
   "source": [
    "# Création du vecteur d'entrée \n",
    "entree = np.zeros((num_examples, MAX_SEQ_SIZE, 300))\n",
    "for i, sentence in enumerate(vec_word):\n",
    "    for j, word in enumerate(sentence):\n",
    "        if word:\n",
    "            entree[i, j] = get_embedding(word)\n",
    "        else:\n",
    "            entree[i, j] = np.zeros(300)\n",
    "\n",
    "print(\"entree shape : \", entree.shape)\n",
    "print(\"sortie shape : \", sortie.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label.extract_label(\"atis.train\")\n",
    "label_one_hot_dict = {label_: label.get_vector_from_label(label_) for label_ in labels} # création d'un dictionnaire associant chaque label à son vecteur one hot \n",
    "\n",
    "nbLabels = len(labels)\n",
    "embedding_size = len(entree[0][0])\n",
    "\n",
    "tailleDictionnaire = emb_spacy.get_size_dict()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sortie[0])\n",
    "sortie_one_hot = np.zeros((sortie.shape[0], sortie.shape[1], len(label_one_hot_dict['O'])), dtype=int)\n",
    "zero_vec = np.zeros(len(label_one_hot_dict['O']), dtype=int)\n",
    "for i in range(sortie.shape[0]):\n",
    "    for j in range(sortie.shape[1]):\n",
    "        label = sortie[i, j]\n",
    "        if label == '0':\n",
    "            sortie_one_hot[i, j] = zero_vec\n",
    "        else:\n",
    "            sortie_one_hot[i, j] = label_one_hot_dict[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ok\n",
      "create ok\n",
      "compil ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,449</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m219,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m81\u001b[0m)         │        \u001b[38;5;34m10,449\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m81\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230,097</span> (898.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m230,097\u001b[0m (898.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230,097</span> (898.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m230,097\u001b[0m (898.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    'hidden_size': 128, # Taille de la couche cachée du RNN\n",
    "    'dropout_rate': 0.5,  # Taux de dropout\n",
    "    'nb_labels': nbLabels\n",
    "}  \n",
    "\n",
    "# Définir l'entrée du modèle\n",
    "# pas besoin de mettre le nb d'ex car il les fait passer un par un \n",
    "input_layer = Input(shape=(MAX_SEQ_SIZE, embedding_size), dtype='float32')\n",
    "\n",
    "# Ajouter une couche LSTM bidirectionnelle\n",
    "# X = Bidirectional(LSTM(units=config['hidden_size'], return_sequences=True))(input_layer)\n",
    "X = LSTM(units=config['hidden_size'], return_sequences=True)(input_layer)\n",
    "X = Dropout(config['dropout_rate'])(X)\n",
    "# X = LSTM(units = 128)(X)\n",
    "# X = Dropout(config['dropout_rate'])(X)\n",
    "\n",
    "X = Dense(units=config['nb_labels'])(X)\n",
    "X = Activation(activation='softmax')(X)\n",
    "print('config ok')\n",
    "\n",
    "# Création du model\n",
    "model = Model(inputs=input_layer, outputs=X)\n",
    "print(\"create ok\")\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "# NB : j'ai enlevé sparse car j'ai fait un vecteur one hot en sortie et sparse c'est pour quand c'est pas des one hot\n",
    "print(\"compil ok\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle LSTM\n",
    "- x : entree de la forme nb_example x MAX_SEQ_SIZE x embedding_size\n",
    "- y : sortie de la forme nb_example x MAX_SEQ_SIZE\n",
    "- batch_size : nb d'échantillon à utiliser à chaque itération lors de l'entrainement\n",
    "    - un batch_size + gd = accélère l'entrainement mais besoin de + de mémoire GPU\n",
    "    - plus petit = ralentit l'entrainement mais meilleure convergence du modèle\n",
    "- epochs : nb d'itération sur l'ens des données d'entrainement \n",
    "- validation_split : spécifie le fraction des données à utiliser comme données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.1659 - loss: 0.6732 - precision_4: 0.8403 - recall_4: 0.2006 - val_accuracy: 0.9548 - val_loss: 0.2175 - val_precision_4: 0.9327 - val_recall_4: 0.7463\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.3911 - loss: 0.2078 - precision_4: 0.9515 - recall_4: 0.7769 - val_accuracy: 0.9700 - val_loss: 0.1573 - val_precision_4: 0.9575 - val_recall_4: 0.8352\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4583 - loss: 0.1415 - precision_4: 0.9734 - recall_4: 0.8402 - val_accuracy: 0.9654 - val_loss: 0.1320 - val_precision_4: 0.9608 - val_recall_4: 0.8500\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 147ms/step - accuracy: 0.4232 - loss: 0.1182 - precision_4: 0.9745 - recall_4: 0.8624 - val_accuracy: 0.9739 - val_loss: 0.1169 - val_precision_4: 0.9624 - val_recall_4: 0.8584\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 142ms/step - accuracy: 0.4435 - loss: 0.1032 - precision_4: 0.9778 - recall_4: 0.8758 - val_accuracy: 0.9754 - val_loss: 0.1060 - val_precision_4: 0.9647 - val_recall_4: 0.8683\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - accuracy: 0.4252 - loss: 0.0937 - precision_4: 0.9795 - recall_4: 0.8859 - val_accuracy: 0.9772 - val_loss: 0.0972 - val_precision_4: 0.9657 - val_recall_4: 0.8733\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 139ms/step - accuracy: 0.4682 - loss: 0.0807 - precision_4: 0.9772 - recall_4: 0.8973 - val_accuracy: 0.9790 - val_loss: 0.0909 - val_precision_4: 0.9723 - val_recall_4: 0.8768\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 140ms/step - accuracy: 0.4588 - loss: 0.0804 - precision_4: 0.9759 - recall_4: 0.9031 - val_accuracy: 0.9798 - val_loss: 0.0867 - val_precision_4: 0.9694 - val_recall_4: 0.8789\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 141ms/step - accuracy: 0.4625 - loss: 0.0716 - precision_4: 0.9752 - recall_4: 0.9070 - val_accuracy: 0.9809 - val_loss: 0.0836 - val_precision_4: 0.9732 - val_recall_4: 0.8820\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.4409 - loss: 0.0710 - precision_4: 0.9774 - recall_4: 0.9064 - val_accuracy: 0.9817 - val_loss: 0.0808 - val_precision_4: 0.9735 - val_recall_4: 0.8837\n",
      "training ok\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=entree, y=sortie_one_hot, batch_size=128, epochs=10, validation_split=0.2)\n",
    "print('training ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ok\n",
      "create ok\n",
      "compil ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">165,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,449</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m165,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m81\u001b[0m)         │        \u001b[38;5;34m10,449\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m81\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,569</span> (685.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m175,569\u001b[0m (685.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,569</span> (685.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m175,569\u001b[0m (685.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    'hidden_size': 128, # Taille de la couche cachée du RNN\n",
    "    'dropout_rate': 0.5,  # Taux de dropout\n",
    "    'nb_labels': nbLabels\n",
    "}  \n",
    "\n",
    "# Définir l'entrée du modèle\n",
    "# pas besoin de mettre le nb d'ex car il les fait passer un par un \n",
    "input_layer = Input(shape=(MAX_SEQ_SIZE, embedding_size), dtype='float32')\n",
    "\n",
    "# Ajouter une couche LSTM bidirectionnelle\n",
    "# X = Bidirectional(LSTM(units=config['hidden_size'], return_sequences=True))(input_layer)\n",
    "X = GRU(units=config['hidden_size'], return_sequences=True)(input_layer)\n",
    "X = Dropout(config['dropout_rate'])(X)\n",
    "# X = LSTM(units = 128)(X)\n",
    "# X = Dropout(config['dropout_rate'])(X)\n",
    "\n",
    "X = Dense(units=config['nb_labels'])(X)\n",
    "X = Activation(activation='softmax')(X)\n",
    "print('config ok')\n",
    "\n",
    "# Création du model\n",
    "model_GRU = Model(inputs=input_layer, outputs=X)\n",
    "print(\"create ok\")\n",
    "\n",
    "# Compilation du modèle\n",
    "model_GRU.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "# NB : j'ai enlevé sparse car j'ai fait un vecteur one hot en sortie et sparse c'est pour quand c'est pas des one hot\n",
    "print(\"compil ok\")\n",
    "print(model_GRU.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.1466 - loss: 0.6987 - precision_5: 0.7676 - recall_5: 0.2708 - val_accuracy: 0.5356 - val_loss: 0.2301 - val_precision_5: 0.9401 - val_recall_5: 0.7162\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.3210 - loss: 0.2369 - precision_5: 0.9355 - recall_5: 0.7364 - val_accuracy: 0.9368 - val_loss: 0.1873 - val_precision_5: 0.9536 - val_recall_5: 0.8019\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.3584 - loss: 0.1954 - precision_5: 0.9502 - recall_5: 0.7785 - val_accuracy: 0.9468 - val_loss: 0.1620 - val_precision_5: 0.9608 - val_recall_5: 0.8336\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.3505 - loss: 0.1648 - precision_5: 0.9633 - recall_5: 0.8106 - val_accuracy: 0.9575 - val_loss: 0.1468 - val_precision_5: 0.9619 - val_recall_5: 0.8452\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.3573 - loss: 0.1446 - precision_5: 0.9678 - recall_5: 0.8329 - val_accuracy: 0.9705 - val_loss: 0.1342 - val_precision_5: 0.9632 - val_recall_5: 0.8541\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.3689 - loss: 0.1346 - precision_5: 0.9657 - recall_5: 0.8463 - val_accuracy: 0.9739 - val_loss: 0.1253 - val_precision_5: 0.9643 - val_recall_5: 0.8603\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.3581 - loss: 0.1180 - precision_5: 0.9717 - recall_5: 0.8639 - val_accuracy: 0.9753 - val_loss: 0.1177 - val_precision_5: 0.9667 - val_recall_5: 0.8651\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.3663 - loss: 0.1112 - precision_5: 0.9726 - recall_5: 0.8717 - val_accuracy: 0.9760 - val_loss: 0.1118 - val_precision_5: 0.9668 - val_recall_5: 0.8676\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.3657 - loss: 0.1059 - precision_5: 0.9738 - recall_5: 0.8771 - val_accuracy: 0.9764 - val_loss: 0.1075 - val_precision_5: 0.9686 - val_recall_5: 0.8724\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.3687 - loss: 0.0993 - precision_5: 0.9732 - recall_5: 0.8826 - val_accuracy: 0.9775 - val_loss: 0.1031 - val_precision_5: 0.9725 - val_recall_5: 0.8742\n",
      "training ok\n"
     ]
    }
   ],
   "source": [
    "model_GRU.fit(x=entree, y=sortie_one_hot, batch_size=128, epochs=10, validation_split=0.2)\n",
    "print('training ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples : 1033\n",
      "Taille maximale de la phrase : 32\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_corpus\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data_test = file.readlines()\n",
    "    \n",
    "num_examples_test, MAX_SEQ_SIZE_TEST = count_examples_and_max_length(data_test)\n",
    "\n",
    "\n",
    "vec_word_test, label_test_real = pad_sentences_from_file(\"test_corpus\", MAX_SEQ_SIZE)\n",
    "\n",
    "print(\"Nombre d'exemples :\", num_examples_test) \n",
    "print(\"Taille maximale de la phrase :\", MAX_SEQ_SIZE_TEST)\n",
    "\n",
    "# Création du vecteur d'entrée \n",
    "test_data_input = np.zeros((num_examples_test, MAX_SEQ_SIZE, 300))\n",
    "for i, sentence in enumerate(vec_word_test):\n",
    "    for j, word in enumerate(sentence):\n",
    "        if word:\n",
    "            test_data_input[i, j] = get_embedding(word)\n",
    "        else:\n",
    "            test_data_input[i, j] = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 41, 300)\n",
      "(1033, 41)\n",
      "(3945, 41, 300)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_input.shape)\n",
    "print(label_test_real.shape)\n",
    "print(entree.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 41, 81)\n"
     ]
    }
   ],
   "source": [
    "label_test_real_one_hot = np.zeros((label_test_real.shape[0], label_test_real.shape[1], len(label_one_hot_dict['O'])), dtype=int)\n",
    "zero_vec = np.zeros(len(label_one_hot_dict['O']), dtype=int)\n",
    "for i in range(label_test_real.shape[0]):\n",
    "    for j in range(label_test_real.shape[1]):\n",
    "        label = label_test_real[i, j]\n",
    "        if label == '0':\n",
    "            label_test_real_one_hot[i, j] = zero_vec\n",
    "        else:\n",
    "            label_test_real_one_hot[i, j] = label_one_hot_dict[label]\n",
    "\n",
    "print(label_test_real_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec le modèle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "(1033, 41, 81)\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(test_data_input)\n",
    "\n",
    "print(test_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_index = np.argmax(test_predictions, axis=-1)\n",
    "# print(predicted_labels_index[10])\n",
    "predicted_labels = [[labels[idx] for idx in sample] for sample in predicted_labels_index]\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "# print(predicted_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9827 - loss: 0.0830 - precision_4: 0.9681 - recall_4: 0.8913\n"
     ]
    }
   ],
   "source": [
    "_ = model.evaluate(test_data_input, label_test_real_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_to_file(file_path, vec_word_test, predicted_labels, label_test_real=None, exam=False):\n",
    "    if not exam:\n",
    "        with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "            for words, real_labels, predicted_labels in zip(vec_word_test, label_test_real, predicted_labels):\n",
    "                for word, real_label, predicted_label in zip(words, real_labels, predicted_labels):\n",
    "                    if real_label == '0' or word == '0':\n",
    "                        break\n",
    "                    word_length = max(len(word), 8)\n",
    "                    file.write(f\"{word.ljust(word_length)}\\t{real_label.ljust(10)}\\t{predicted_label}\\n\")\n",
    "                file.write(\"===========================================================\\n\")\n",
    "    else:\n",
    "        with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "            for words, predicted_labels in zip(vec_word_test, predicted_labels):\n",
    "                for word, predicted_label in zip(words, predicted_labels):\n",
    "                    if word == '0':\n",
    "                        break\n",
    "                    word_length = max(len(word), 8)\n",
    "                    file.write(f\"{word.ljust(word_length)}\\t{predicted_label}\\n\")\n",
    "                file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_to_file(\"results/predictions_LSTM.txt\", vec_word_test, label_test_real, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec le modèle GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "(1033, 41, 81)\n"
     ]
    }
   ],
   "source": [
    "test_predictions_GRU = model_GRU.predict(test_data_input)\n",
    "\n",
    "print(test_predictions_GRU.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_index_GRU = np.argmax(test_predictions_GRU, axis=-1)\n",
    "# print(predicted_labels_index[10])\n",
    "predicted_labels_GRU = [[labels[idx] for idx in sample] for sample in predicted_labels_index_GRU]\n",
    "predicted_labels_GRU = np.array(predicted_labels_GRU)\n",
    "# print(predicted_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9774 - loss: 0.1122 - precision_5: 0.9650 - recall_5: 0.8796\n"
     ]
    }
   ],
   "source": [
    "_ = model_GRU.evaluate(test_data_input, label_test_real_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_to_file(\"results/predictions_GRU.txt\", vec_word_test, label_test_real, predicted_labels_GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE EXAMEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration des données à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples : 893\n",
      "Taille maximale de la phrase : 29\n"
     ]
    }
   ],
   "source": [
    "with open(\"atis.test.talil.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data_exam = file.readlines()\n",
    "    \n",
    "num_examples_exam, MAX_SEQ_SIZE_EXAM = count_examples_and_max_length(data_exam)\n",
    "\n",
    "\n",
    "vec_word_exam = pad_sentences_from_file(\"atis.test.talil.txt\", MAX_SEQ_SIZE, exam=True)\n",
    "\n",
    "print(\"Nombre d'exemples :\", num_examples_exam) \n",
    "print(\"Taille maximale de la phrase :\", MAX_SEQ_SIZE_EXAM)\n",
    "\n",
    "# Création du vecteur d'entrée \n",
    "exam_data_input = np.zeros((num_examples_exam, MAX_SEQ_SIZE, 300))\n",
    "for i, sentence in enumerate(vec_word_exam):\n",
    "    for j, word in enumerate(sentence):\n",
    "        if word:\n",
    "            exam_data_input[i, j] = get_embedding(word)\n",
    "        else:\n",
    "            exam_data_input[i, j] = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(893, 41, 300)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_data_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédictions avec LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "exam_predictions = model.predict(exam_data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_index = np.argmax(exam_predictions, axis=-1)\n",
    "# print(predicted_labels_index[10])\n",
    "predicted_labels = [[labels[idx] for idx in sample] for sample in predicted_labels_index]\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "# print(predicted_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_to_file(\"results/predictions_LSTM_EXAM.txt\", vec_word_exam, predicted_labels, exam=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction avec GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "exam_predictions_GRU = model_GRU.predict(exam_data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_index = np.argmax(exam_predictions_GRU, axis=-1)\n",
    "# print(predicted_labels_index[10])\n",
    "predicted_labels = [[labels[idx] for idx in sample] for sample in predicted_labels_index]\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "# print(predicted_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions_to_file(\"results/predictions_GRU_EXAM.txt\", vec_word_exam, predicted_labels, exam=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
