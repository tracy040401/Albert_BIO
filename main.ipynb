{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 16:05:29.473195: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 16:05:29.474903: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-26 16:05:29.578345: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-26 16:05:29.957728: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 16:05:31.385801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "import numpy as np\n",
    "import emb_spacy\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, TimeDistributed, Bidirectional\n",
    "\n",
    "\n",
    "from emb_spacy import get_embedding\n",
    "from input import count_examples_and_max_length, pad_sentences_from_file\n",
    "import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples : 3945\n",
      "Taille maximale de la phrase : 41\n",
      "vecteur :  (3945, 41)\n"
     ]
    }
   ],
   "source": [
    "# Ouverture en lecture des données\n",
    "with open(\"train_corpus\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Compter les exemples et trouver la taille maximale\n",
    "num_examples, MAX_SEQ_SIZE = count_examples_and_max_length(data)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Nombre d'exemples :\", num_examples) \n",
    "print(\"Taille maximale de la phrase :\", MAX_SEQ_SIZE)\n",
    "\n",
    "vec_word, sortie = pad_sentences_from_file(\"train_corpus\", MAX_SEQ_SIZE)\n",
    "print(\"vecteur : \", vec_word.shape)\n",
    "# vec_word.shape : (3945, 41)\n",
    "# sortie.shape : (3945, 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des vecteurs d'entrée et de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entree shape :  (3945, 41, 300)\n",
      "sortie shape :  (3945, 41)\n"
     ]
    }
   ],
   "source": [
    "# Création du vecteur d'entrée \n",
    "entree = np.zeros((num_examples, MAX_SEQ_SIZE, 300))\n",
    "for i, sentence in enumerate(vec_word):\n",
    "    for j, word in enumerate(sentence):\n",
    "        if word:\n",
    "            entree[i, j] = get_embedding(word)\n",
    "        else:\n",
    "            entree[i, j] = np.zeros(300)\n",
    "\n",
    "print(\"entree shape : \", entree.shape)\n",
    "print(\"sortie shape : \", sortie.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustement du vecteur de sortie\n",
    "# TODO : faut mettre en vecteur numérique chacune des étiquettes\n",
    "sortie_one_hot = np.array([[[label.get_vector_from_label(label_i) for label_i in labels] for labels in sentence_labels] for sentence_labels in sortie])\n",
    "\n",
    "print(sortie_one_hot[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ok\n",
      "create ok\n",
      "compil ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 16:05:59.876308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-26 16:05:59.876929: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,817</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m439,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m81\u001b[0m)         │        \u001b[38;5;34m20,817\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m81\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">460,113</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m460,113\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">460,113</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m460,113\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "labels = label.extract_label(\"atis.train\")\n",
    "#print(\"LABELS :\", labels)\n",
    "nbLabels = len(labels)  # Nombre d'étiquettes potentielles\n",
    "embedding_size = len(entree[0][0])\n",
    "\n",
    "tailleDictionnaire = emb_spacy.get_size_dict()  # Taille du dictionnaire de mots\n",
    "config = {\n",
    "    'hidden_size': 128, # Taille de la couche cachée du RNN\n",
    "    'dropout_ rate': 0.5,  # Taux de dropout\n",
    "    'nb_labels': nbLabels\n",
    "}  \n",
    "\n",
    "# Définir l'entrée du modèle\n",
    "# pas besoin de mettre le nb d'ex car il les fait passer un par un \n",
    "input_layer = Input(shape=(MAX_SEQ_SIZE, embedding_size), dtype='float32')\n",
    "\n",
    "# Ajouter une couche LSTM bidirectionnelle\n",
    "X = Bidirectional(LSTM(units=config['hidden_size'], return_sequences=True))(input_layer)\n",
    "X = Dropout(config['dropout_ rate'])(X)\n",
    "# X = LSTM(units = 128)(X)\n",
    "# X = Dropout(config['dropout_ rate'])(X)\n",
    "\n",
    "X = Dense(units=config['nb_labels'])(X)\n",
    "X = Activation(activation='softmax')(X)\n",
    "print('config ok')\n",
    "\n",
    "# Création du model\n",
    "model = Model(inputs=input_layer, outputs=X)\n",
    "print(\"create ok\")\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"compil ok\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle LSTM\n",
    "- x : entree de la forme nb_example x MAX_SEQ_SIZE x embedding_size\n",
    "- y : sortie de la forme nb_example x MAX_SEQ_SIZE\n",
    "- batch_size : nb d'échantillon à utiliser à chaque itération lors de l'entrainement\n",
    "    - un batch_size + gd = accélère l'entrainement mais besoin de + de mémoire GPU\n",
    "    - plus petit = ralentit l'entrainement mais meilleure convergence du modèle\n",
    "- epochs : nb d'itération sur l'ens des données d'entrainement \n",
    "- validation_split : spécifie le fraction des données à utiliser comme données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=entree, y=sortie, batch_size=128, epochs=10, validation_split=0.2)\n",
    "print('training ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
