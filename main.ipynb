{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import numpy as np\n",
    "import emb_spacy\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional\n",
    "from keras.metrics import Accuracy, Precision, Recall, F1Score, MeanSquaredError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from emb_spacy import get_embedding\n",
    "from input import count_examples_and_max_length, pad_sentences_from_file\n",
    "import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples : 3945\n",
      "Taille maximale de la phrase : 41\n",
      "vecteur :  (3945, 41)\n"
     ]
    }
   ],
   "source": [
    "# Ouverture en lecture des données\n",
    "with open(\"train_corpus\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Compter les exemples et trouver la taille maximale\n",
    "num_examples, MAX_SEQ_SIZE = count_examples_and_max_length(data)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Nombre d'exemples :\", num_examples) \n",
    "print(\"Taille maximale de la phrase :\", MAX_SEQ_SIZE)\n",
    "\n",
    "vec_word, sortie = pad_sentences_from_file(\"train_corpus\", MAX_SEQ_SIZE)\n",
    "print(\"vecteur : \", vec_word.shape)\n",
    "# vec_word.shape : (3945, 41)\n",
    "# sortie.shape : (3945, 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des vecteurs d'entrée et de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entree shape :  (3945, 41, 300)\n",
      "sortie shape :  (3945, 41)\n"
     ]
    }
   ],
   "source": [
    "# Création du vecteur d'entrée \n",
    "entree = np.zeros((num_examples, MAX_SEQ_SIZE, 300))\n",
    "for i, sentence in enumerate(vec_word):\n",
    "    for j, word in enumerate(sentence):\n",
    "        if word:\n",
    "            entree[i, j] = get_embedding(word)\n",
    "        else:\n",
    "            entree[i, j] = np.zeros(300)\n",
    "\n",
    "print(\"entree shape : \", entree.shape)\n",
    "print(\"sortie shape : \", sortie.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label.extract_label(\"atis.train\")\n",
    "label_one_hot_dict = {label_: label.get_vector_from_label(label_) for label_ in labels} # création d'un dictionnaire associant chaque label à son vecteur one hot \n",
    "\n",
    "#print(\"LABELS :\", labels)\n",
    "nbLabels = len(labels)  # Nombre d'étiquettes potentielles\n",
    "embedding_size = len(entree[0][0])\n",
    "\n",
    "tailleDictionnaire = emb_spacy.get_size_dict()  # Taille du dictionnaire de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sortie[0])\n",
    "sortie_one_hot = np.zeros((sortie.shape[0], sortie.shape[1], len(label_one_hot_dict['O'])), dtype=int)\n",
    "zero_vec = np.zeros(len(label_one_hot_dict['O']), dtype=int)\n",
    "for i in range(sortie.shape[0]):\n",
    "    for j in range(sortie.shape[1]):\n",
    "        label = sortie[i, j]\n",
    "        if label == '0':\n",
    "            sortie_one_hot[i, j] = zero_vec\n",
    "        else:\n",
    "            sortie_one_hot[i, j] = label_one_hot_dict[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sortie_one_hot.npy', sortie_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'O', 'O', 'O', 'O', 'B-cost_relative', 'O', 'O',\n",
       "       'B-fromloc.city_name', 'B-fromloc.state_code', 'O',\n",
       "       'B-toloc.city_name', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortie[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3945, 41, 81)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortie_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config ok\n",
      "create ok\n",
      "compil ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">439,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,817</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m439,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m81\u001b[0m)         │        \u001b[38;5;34m20,817\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m81\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">460,113</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m460,113\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">460,113</span> (1.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m460,113\u001b[0m (1.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    'hidden_size': 128, # Taille de la couche cachée du RNN\n",
    "    'dropout_rate': 0.5,  # Taux de dropout\n",
    "    'nb_labels': nbLabels\n",
    "}  \n",
    "\n",
    "# Définir l'entrée du modèle\n",
    "# pas besoin de mettre le nb d'ex car il les fait passer un par un \n",
    "input_layer = Input(shape=(MAX_SEQ_SIZE, embedding_size), dtype='float32')\n",
    "\n",
    "# Ajouter une couche LSTM bidirectionnelle\n",
    "X = Bidirectional(LSTM(units=config['hidden_size'], return_sequences=True))(input_layer)\n",
    "X = Dropout(config['dropout_rate'])(X)\n",
    "# X = LSTM(units = 128)(X)\n",
    "# X = Dropout(config['dropout_rate'])(X)\n",
    "\n",
    "X = Dense(units=config['nb_labels'])(X)\n",
    "X = Activation(activation='softmax')(X)\n",
    "print('config ok')\n",
    "\n",
    "# Création du model\n",
    "model = Model(inputs=input_layer, outputs=X)\n",
    "print(\"create ok\")\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=nbLabels)])\n",
    "# NB : j'ai enlevé sparse car j'ai fait un vecteur one hot en sortie et sparse c'est pour quand c'est pas des one hot\n",
    "print(\"compil ok\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle LSTM\n",
    "- x : entree de la forme nb_example x MAX_SEQ_SIZE x embedding_size\n",
    "- y : sortie de la forme nb_example x MAX_SEQ_SIZE\n",
    "- batch_size : nb d'échantillon à utiliser à chaque itération lors de l'entrainement\n",
    "    - un batch_size + gd = accélère l'entrainement mais besoin de + de mémoire GPU\n",
    "    - plus petit = ralentit l'entrainement mais meilleure convergence du modèle\n",
    "- epochs : nb d'itération sur l'ens des données d'entrainement \n",
    "- validation_split : spécifie le fraction des données à utiliser comme données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - accuracy: 0.2280 - accuracy_1: 0.0000e+00 - loss: 0.5729 - precision_1: 0.8572 - recall: 0.3716 - val_accuracy: 0.9637 - val_accuracy_1: 0.0000e+00 - val_loss: 0.1657 - val_precision_1: 0.9467 - val_recall: 0.8215\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.4015 - accuracy_1: 0.0000e+00 - loss: 0.1469 - precision_1: 0.9617 - recall: 0.8383 - val_accuracy: 0.9724 - val_accuracy_1: 0.0000e+00 - val_loss: 0.1214 - val_precision_1: 0.9590 - val_recall: 0.8646\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.4141 - accuracy_1: 0.0000e+00 - loss: 0.1029 - precision_1: 0.9686 - recall: 0.8817 - val_accuracy: 0.9783 - val_accuracy_1: 0.0000e+00 - val_loss: 0.1014 - val_precision_1: 0.9642 - val_recall: 0.8749\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.4153 - accuracy_1: 0.0000e+00 - loss: 0.0800 - precision_1: 0.9754 - recall: 0.8996 - val_accuracy: 0.9804 - val_accuracy_1: 0.0000e+00 - val_loss: 0.0897 - val_precision_1: 0.9687 - val_recall: 0.8839\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.3885 - accuracy_1: 0.0000e+00 - loss: 0.0712 - precision_1: 0.9791 - recall: 0.9113 - val_accuracy: 0.9819 - val_accuracy_1: 0.0000e+00 - val_loss: 0.0819 - val_precision_1: 0.9714 - val_recall: 0.8914\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.4000 - accuracy_1: 0.0000e+00 - loss: 0.0616 - precision_1: 0.9773 - recall: 0.9211 - val_accuracy: 0.9828 - val_accuracy_1: 0.0000e+00 - val_loss: 0.0757 - val_precision_1: 0.9726 - val_recall: 0.8998\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.3832 - accuracy_1: 0.0000e+00 - loss: 0.0557 - precision_1: 0.9788 - recall: 0.9254 - val_accuracy: 0.9843 - val_accuracy_1: 0.0000e+00 - val_loss: 0.0711 - val_precision_1: 0.9733 - val_recall: 0.9056\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.3895 - accuracy_1: 0.0000e+00 - loss: 0.0510 - precision_1: 0.9785 - recall: 0.9321 - val_accuracy: 0.9853 - val_accuracy_1: 0.0000e+00 - val_loss: 0.0671 - val_precision_1: 0.9745 - val_recall: 0.9131\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.3972 - accuracy_1: 0.0000e+00 - loss: 0.0473 - precision_1: 0.9796 - recall: 0.9375 - val_accuracy: 0.9855 - val_accuracy_1: 0.0000e+00 - val_loss: 0.0638 - val_precision_1: 0.9731 - val_recall: 0.9173\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.4100 - accuracy_1: 0.0000e+00 - loss: 0.0465 - precision_1: 0.9786 - recall: 0.9393 - val_accuracy: 0.9865 - val_accuracy_1: 0.0000e+00 - val_loss: 0.0604 - val_precision_1: 0.9733 - val_recall: 0.9210\n",
      "training ok\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=entree, y=sortie_one_hot, batch_size=128, epochs=10, validation_split=0.2)\n",
    "print('training ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples : 1033\n",
      "Taille maximale de la phrase : 32\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_corpus\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data_test = file.readlines()\n",
    "    \n",
    "num_examples_test, MAX_SEQ_SIZE_TEST = count_examples_and_max_length(data_test)\n",
    "\n",
    "\n",
    "vec_word_test, label_test_real = pad_sentences_from_file(\"test_corpus\", MAX_SEQ_SIZE)\n",
    "\n",
    "print(\"Nombre d'exemples :\", num_examples_test) \n",
    "print(\"Taille maximale de la phrase :\", MAX_SEQ_SIZE_TEST)\n",
    "\n",
    "# Création du vecteur d'entrée \n",
    "test_data_input = np.zeros((num_examples_test, MAX_SEQ_SIZE, 300))\n",
    "for i, sentence in enumerate(vec_word_test):\n",
    "    for j, word in enumerate(sentence):\n",
    "        if word:\n",
    "            test_data_input[i, j] = get_embedding(word)\n",
    "        else:\n",
    "            test_data_input[i, j] = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 41, 300)\n",
      "(1033, 41)\n",
      "(3945, 41, 300)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_input.shape)\n",
    "print(label_test_real.shape)\n",
    "print(entree.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1033, 41, 81)\n"
     ]
    }
   ],
   "source": [
    "label_test_real_one_hot = np.zeros((label_test_real.shape[0], label_test_real.shape[1], len(label_one_hot_dict['O'])), dtype=int)\n",
    "zero_vec = np.zeros(len(label_one_hot_dict['O']), dtype=int)\n",
    "for i in range(label_test_real.shape[0]):\n",
    "    for j in range(label_test_real.shape[1]):\n",
    "        label = label_test_real[i, j]\n",
    "        if label == '0':\n",
    "            label_test_real_one_hot[i, j] = zero_vec\n",
    "        else:\n",
    "            label_test_real_one_hot[i, j] = label_one_hot_dict[label]\n",
    "\n",
    "print(label_test_real_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "(1033, 41, 81)\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(test_data_input)\n",
    "\n",
    "print(test_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'O' 'O' 'O' 'O' 'B-fromloc.city_name' 'O' 'B-toloc.city_name' 'O' 'O'\n",
      " 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n",
      " 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_index = np.argmax(test_predictions, axis=-1)\n",
    "\n",
    "predicted_labels = [[labels[idx] for idx in sample] for sample in predicted_labels_index]\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "print(predicted_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'O' 'O' 'O' 'O' 'B-fromloc.city_name' 'O' 'B-toloc.city_name' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "print(label_test_real[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9854 - accuracy_1: 0.0000e+00 - loss: 0.0628 - precision_1: 0.9670 - recall: 0.9248\n",
      "Loss on test data: 0.04819686338305473\n",
      "Accuracy on test data: 0.9623639583587646\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data_input, label_test_real_one_hot)\n",
    "\n",
    "print(\"Loss on test data:\", test_loss)\n",
    "print(\"Accuracy on test data:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
